{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import pl_bolts\n",
    "from relative_performer.train import RelativePerformerModel\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/hornm/Projects/RelativePerformer/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pl_bolts.datamodules.MNISTDataModule('../data/MNIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = dataset.train_dataloader()\n",
    "batch = next(train_loader.__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = batch\n",
    "x = x.permute(0, 2, 3, 1)\n",
    "x = x[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RelativePerformerModel(dim=128, heads=1, depth=1, in_features=1, max_pos=28, pos_dims=2, pos_scales=8, num_classes=10, embedding_type='linear', no_projection=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_flat, positions = model._flatten_to_sequence(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1420f87f0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(model._compute_positional_embeddings(positions[:, :28, [1]]).detach().numpy()[0], aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = model(x).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "out2 = model(x_flat, positions).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "out3 = model(x_flat, positions + torch.ones(*positions.shape)).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(out1, out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(out1, out3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.18364005,  0.40394008,  0.12559885,  1.212065  , -0.3024696 ,\n",
       "        -0.23812824, -0.6652707 ,  0.00577746, -0.44367722, -0.1302074 ],\n",
       "       dtype=float32),\n",
       " array([-0.18364005,  0.40394008,  0.12559885,  1.212065  , -0.3024696 ,\n",
       "        -0.23812824, -0.6652707 ,  0.00577746, -0.44367722, -0.1302074 ],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1[0], out3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  1.],\n",
       "         [ 1.,  2.],\n",
       "         [ 1.,  3.],\n",
       "         ...,\n",
       "         [28., 26.],\n",
       "         [28., 27.],\n",
       "         [28., 28.]]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions + torch.ones(*positions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "projection_matrix = model.performer.net.layers[0][0].fn.to_q._build_positional_projection_matrix()\n",
    "print(projection_matrix.shape)\n",
    "# projection_matrix = projection_matrix[:, :32, :32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-2.6894, -4.8353],\n",
      "          [ 1.5564, -2.6894]]]], grad_fn=<UnsafeViewBackward>)\n",
      "tensor([[[[-2.6894, -4.8353],\n",
      "          [ 1.5564, -2.6894]]]], grad_fn=<UnsafeViewBackward>)\n"
     ]
    }
   ],
   "source": [
    "from einops import repeat\n",
    "def compute_dot_prod(i1, i2, j1, j2):\n",
    "    positions = torch.Tensor([[i1, i2], [j1, j2]])[None]\n",
    "    from einops import rearrange\n",
    "    encodings = model._compute_positional_embeddings(positions)\n",
    "    k = repeat(encodings, 'b n d -> b h n d', h=1)\n",
    "    encodings = rearrange(encodings, 'b n d -> b n 1 1 d')\n",
    "    encodings = encodings.matmul(projection_matrix)\n",
    "    encodings = rearrange(encodings, 'b n h 1 d -> b h n d')\n",
    "    return encodings.matmul(k.transpose(-1, -2))\n",
    "print(compute_dot_prod(0, 0, 1, 1))\n",
    "print(compute_dot_prod(128, 127, 129, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from relative_performer.constrained_relative_encoding import ConstrainedLinear, IdentityLinear\n",
    "\n",
    "to_q, to_k = ConstrainedLinear(1, 2, 16, 2), IdentityLinear(1, 2, 16, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16, 2, 2])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_q._build_positional_projection_matrix_test().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1380, -0.3112],\n",
       "         [ 0.3112,  0.1380]],\n",
       "\n",
       "        [[ 0.2101, -1.5771],\n",
       "         [ 1.5771,  0.2101]],\n",
       "\n",
       "        [[-0.9529, -0.9616],\n",
       "         [ 0.9616, -0.9529]],\n",
       "\n",
       "        [[-0.0875,  1.3311],\n",
       "         [-1.3311, -0.0875]],\n",
       "\n",
       "        [[ 1.1248,  2.2364],\n",
       "         [-2.2364,  1.1248]],\n",
       "\n",
       "        [[-0.9593, -0.4814],\n",
       "         [ 0.4814, -0.9593]],\n",
       "\n",
       "        [[ 0.9062,  0.4642],\n",
       "         [-0.4642,  0.9062]],\n",
       "\n",
       "        [[ 2.0007,  1.3315],\n",
       "         [-1.3315,  2.0007]],\n",
       "\n",
       "        [[-0.2575, -0.6542],\n",
       "         [ 0.6542, -0.2575]],\n",
       "\n",
       "        [[ 0.0039,  1.6808],\n",
       "         [-1.6808,  0.0039]],\n",
       "\n",
       "        [[-1.5500,  2.1098],\n",
       "         [-2.1098, -1.5500]],\n",
       "\n",
       "        [[-0.8114,  0.3042],\n",
       "         [-0.3042, -0.8114]],\n",
       "\n",
       "        [[ 0.6494, -0.1627],\n",
       "         [ 0.1627,  0.6494]],\n",
       "\n",
       "        [[ 0.4672, -0.1172],\n",
       "         [ 0.1172,  0.4672]],\n",
       "\n",
       "        [[ 0.9907, -1.9594],\n",
       "         [ 1.9594,  0.9907]],\n",
       "\n",
       "        [[-0.3136,  1.2583],\n",
       "         [-1.2583, -0.3136]]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_q._build_positional_projection_matrix_test()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1380, -0.3112,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.3112,  0.1380,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.2101,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.9907,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.3136,  1.2583],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -1.2583, -0.3136]],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_q._build_positional_projection_matrix()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.3112,  0.1380,  1.5771,  0.2101,  0.9616, -0.9529, -1.3311,\n",
      "           -0.0875, -2.2364,  1.1248,  0.4814, -0.9593, -0.4642,  0.9062,\n",
      "           -1.3315,  2.0007,  0.6542, -0.2575, -1.6808,  0.0039, -2.1098,\n",
      "           -1.5500, -0.3042, -0.8114,  0.1627,  0.6494,  0.1172,  0.4672,\n",
      "            1.9594,  0.9907, -1.2583, -0.3136],\n",
      "          [ 0.2843, -0.1873,  1.4170, -0.7236,  0.5574, -1.2336, -1.3179,\n",
      "            0.2064, -2.0666,  1.4127,  0.4024, -0.9950, -0.4194,  0.9278,\n",
      "           -1.2718,  2.0392,  0.1368, -0.6896, -1.3807,  0.9586, -2.5244,\n",
      "           -0.6934, -0.4747, -0.7250,  0.2478,  0.6219,  0.1545,  0.4562,\n",
      "            2.0054,  0.8938, -1.2671, -0.2763],\n",
      "          [ 0.3112,  0.1380,  1.5771,  0.2101,  0.9616, -0.9529, -1.3311,\n",
      "           -0.0875, -2.2364,  1.1248,  0.4814, -0.9593, -0.4642,  0.9062,\n",
      "           -1.3315,  2.0007,  0.6542, -0.2575, -1.6808,  0.0039, -2.1098,\n",
      "           -1.5500, -0.3042, -0.8114,  0.1627,  0.6494,  0.1172,  0.4672,\n",
      "            1.9594,  0.9907, -1.2583, -0.3136]],\n",
      "\n",
      "         [[-0.9763,  2.0237,  1.6277, -0.3768, -0.5832,  0.6090,  0.4893,\n",
      "           -1.0463,  0.5493, -1.0614, -0.7235, -1.0593, -1.0035,  1.9529,\n",
      "           -0.8135,  0.6910, -0.7727, -0.7976,  1.5860,  0.3558,  0.5320,\n",
      "            0.2915,  1.2413,  1.1263,  0.0915, -0.8547, -2.2283, -1.6183,\n",
      "            0.1926, -0.1798, -1.2878,  0.1874],\n",
      "          [ 1.1754,  1.9149,  1.1250, -1.2353, -0.3270,  0.7773,  0.2481,\n",
      "           -1.1281,  0.4030, -1.1251, -0.8067, -0.9975, -0.9069,  1.9996,\n",
      "           -0.7927,  0.7148, -1.0886,  0.2193,  1.5071, -0.6088,  0.6010,\n",
      "            0.0821,  1.4581,  0.8268, -0.0232, -0.8593, -2.3516, -1.4332,\n",
      "            0.1835, -0.1890, -1.2817,  0.2254],\n",
      "          [-0.9763,  2.0237,  1.6277, -0.3768, -0.5832,  0.6090,  0.4893,\n",
      "           -1.0463,  0.5493, -1.0614, -0.7235, -1.0593, -1.0035,  1.9529,\n",
      "           -0.8135,  0.6910, -0.7727, -0.7976,  1.5860,  0.3558,  0.5320,\n",
      "            0.2915,  1.2413,  1.1263,  0.0915, -0.8547, -2.2283, -1.6183,\n",
      "            0.1926, -0.1798, -1.2878,  0.1874]]]], grad_fn=<ViewBackward>)\n",
      "tensor([[[[ 1.5588,  1.4989,  1.5588],\n",
      "          [ 1.9927,  1.5588,  1.9927],\n",
      "          [ 1.5588,  1.4989,  1.5588]],\n",
      "\n",
      "         [[ 0.2434,  0.1071,  0.2434],\n",
      "          [-0.8163,  0.2434, -0.8163],\n",
      "          [ 0.2434,  0.1071,  0.2434]]]], grad_fn=<UnsafeViewBackward>)\n",
      "torch.Size([1, 1, 16, 3, 2])\n",
      "torch.Size([1, 2, 16, 3, 2])\n",
      "tensor([[[[ 0.3112,  0.1380,  1.5771,  0.2101,  0.9616, -0.9529, -1.3311,\n",
      "           -0.0875, -2.2364,  1.1248,  0.4814, -0.9593, -0.4642,  0.9062,\n",
      "           -1.3315,  2.0007,  0.6542, -0.2575, -1.6808,  0.0039, -2.1098,\n",
      "           -1.5500, -0.3042, -0.8114,  0.1627,  0.6494,  0.1172,  0.4672,\n",
      "            1.9594,  0.9907, -1.2583, -0.3136],\n",
      "          [ 0.2843, -0.1873,  1.4170, -0.7236,  0.5574, -1.2336, -1.3179,\n",
      "            0.2064, -2.0666,  1.4127,  0.4024, -0.9950, -0.4194,  0.9278,\n",
      "           -1.2718,  2.0392,  0.1368, -0.6896, -1.3807,  0.9586, -2.5244,\n",
      "           -0.6934, -0.4747, -0.7250,  0.2478,  0.6219,  0.1545,  0.4562,\n",
      "            2.0054,  0.8938, -1.2671, -0.2763],\n",
      "          [ 0.3112,  0.1380,  1.5771,  0.2101,  0.9616, -0.9529, -1.3311,\n",
      "           -0.0875, -2.2364,  1.1248,  0.4814, -0.9593, -0.4642,  0.9062,\n",
      "           -1.3315,  2.0007,  0.6542, -0.2575, -1.6808,  0.0039, -2.1098,\n",
      "           -1.5500, -0.3042, -0.8114,  0.1627,  0.6494,  0.1172,  0.4672,\n",
      "            1.9594,  0.9907, -1.2583, -0.3136]],\n",
      "\n",
      "         [[-0.9763,  2.0237,  1.6277, -0.3768, -0.5832,  0.6090,  0.4893,\n",
      "           -1.0463,  0.5493, -1.0614, -0.7235, -1.0593, -1.0035,  1.9529,\n",
      "           -0.8135,  0.6910, -0.7727, -0.7976,  1.5860,  0.3558,  0.5320,\n",
      "            0.2915,  1.2413,  1.1263,  0.0915, -0.8547, -2.2283, -1.6183,\n",
      "            0.1926, -0.1798, -1.2878,  0.1874],\n",
      "          [ 1.1754,  1.9149,  1.1250, -1.2353, -0.3270,  0.7773,  0.2481,\n",
      "           -1.1281,  0.4030, -1.1251, -0.8067, -0.9975, -0.9069,  1.9996,\n",
      "           -0.7927,  0.7148, -1.0886,  0.2193,  1.5071, -0.6088,  0.6010,\n",
      "            0.0821,  1.4581,  0.8268, -0.0232, -0.8593, -2.3516, -1.4332,\n",
      "            0.1835, -0.1890, -1.2817,  0.2254],\n",
      "          [-0.9763,  2.0237,  1.6277, -0.3768, -0.5832,  0.6090,  0.4893,\n",
      "           -1.0463,  0.5493, -1.0614, -0.7235, -1.0593, -1.0035,  1.9529,\n",
      "           -0.8135,  0.6910, -0.7727, -0.7976,  1.5860,  0.3558,  0.5320,\n",
      "            0.2915,  1.2413,  1.1263,  0.0915, -0.8547, -2.2283, -1.6183,\n",
      "            0.1926, -0.1798, -1.2878,  0.1874]]]],\n",
      "       grad_fn=<UnsafeViewBackward>)\n",
      "torch.Size([1, 2, 3, 33]) torch.Size([1, 2, 3, 33])\n",
      "tensor([[[[ 1.5588,  1.4989,  1.5588],\n",
      "          [ 1.9927,  1.5588,  1.9927],\n",
      "          [ 1.5588,  1.4989,  1.5588]],\n",
      "\n",
      "         [[ 0.2434,  0.1071,  0.2434],\n",
      "          [-0.8163,  0.2434, -0.8163],\n",
      "          [ 0.2434,  0.1071,  0.2434]]]], grad_fn=<UnsafeViewBackward>)\n"
     ]
    }
   ],
   "source": [
    "def compute_dot_prod(i1, i2, j1, j2):\n",
    "    positions = torch.Tensor([[i1, i2], [j1, j2], [i1, i2]])[None]\n",
    "    from einops import rearrange\n",
    "    encodings = model._compute_positional_embeddings(positions)\n",
    "    fake_data = torch.zeros(1, 3, 1)\n",
    "    q = to_q(fake_data, encodings)\n",
    "    k = to_k(fake_data, encodings)\n",
    "    # print('q:', q[..., 1:])\n",
    "    encodings = rearrange(encodings, 'b n d -> b n 1 1 d')\n",
    "    encodings = encodings.matmul(to_q._build_positional_projection_matrix())\n",
    "    encodings = rearrange(encodings, 'b n h 1 d -> b h n d')\n",
    "    print(encodings)\n",
    "    # print('encodings:', encodings)\n",
    "    # return encodings.matmul(k[..., 1:].transpose(-1, -2))\n",
    "    return q[..., 1:].matmul(k[..., 1:].transpose(-1, -2))\n",
    "\n",
    "def compute_dot_prod2(i1, i2, j1, j2):\n",
    "    positions = torch.Tensor([[i1, i2], [j1, j2], [i1, i2]])[None]\n",
    "    from einops import rearrange\n",
    "    encodings = model._compute_positional_embeddings(positions)\n",
    "    fake_data = torch.zeros(1, 3, 1)\n",
    "    q = to_q(fake_data, encodings)\n",
    "    k = to_k(fake_data, encodings)\n",
    "    # print('q:', q[..., 1:])\n",
    "    encodings = rearrange(encodings, 'b n (s d) -> b 1 s n d', s=to_q.pos_scales, d=2)\n",
    "    # Format batch_size, heads, scales, instances, 2\n",
    "    print(encodings.shape)\n",
    "    encodings = encodings.matmul(to_q._build_positional_projection_matrix_test())\n",
    "    print(encodings.shape)\n",
    "    encodings = rearrange(encodings, 'b h s n d -> b h n (s d)')\n",
    "    print(encodings)\n",
    "    # print('encodings:', encodings)\n",
    "    # return encodings.matmul(k[..., 1:].transpose(-1, -2))\n",
    "    print(q.shape, k.shape)\n",
    "    return encodings.matmul(k[..., 1:].transpose(-1, -2))\n",
    "\n",
    "print(compute_dot_prod(0, 0, 1, 1))\n",
    "print(compute_dot_prod2(0, 0, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 64])\n",
      "torch.Size([1, 2, 1, 1, 64]) torch.Size([1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.5903e-01,  4.0181e-01, -1.2574e-01, -8.3570e-01, -9.4050e-01,\n",
       "           -9.1811e-01, -6.4195e-01, -4.6085e-01,  8.4565e-01, -6.2729e-01,\n",
       "            1.0973e+00, -1.6743e-03, -2.0976e+00, -5.0637e-02, -7.9917e-01,\n",
       "           -9.1657e-01,  6.4160e-01,  2.4675e-01, -3.6092e-01, -1.8101e-01,\n",
       "            2.0272e+00, -2.6797e-01,  5.3959e-01, -3.0601e+00, -1.0257e+00,\n",
       "           -1.5845e+00,  1.6931e+00,  3.0705e+00, -1.2546e+00,  1.1155e-01,\n",
       "            4.0269e-02, -9.0187e-01,  1.1881e+00,  3.7918e-01,  4.0917e-02,\n",
       "           -9.8124e-01, -1.3745e+00, -1.3507e+00,  8.1876e-01,  4.7793e-01,\n",
       "           -1.2073e+00, -4.8846e-01,  1.2825e+00, -1.6561e+00,  7.4863e-02,\n",
       "           -6.7758e-01,  5.5289e-01,  2.9380e-01, -3.9080e-02,  3.0735e-02,\n",
       "            3.5005e-01, -2.8727e-01, -8.6605e-01,  8.1303e-01,  1.1111e+00,\n",
       "           -2.2804e+00,  1.9332e+00,  4.1228e-01, -4.5921e-01, -1.2461e+00,\n",
       "            5.7522e-01,  2.1921e+00, -8.8906e-01,  4.4382e-01,  9.4483e-02,\n",
       "            1.4089e+00,  1.1852e+00, -1.9048e+00, -2.2895e-01, -1.3653e+00,\n",
       "           -1.3739e+00, -2.1920e-01, -1.0162e+00,  7.4224e-01],\n",
       "          [-1.5903e-01,  4.0181e-01, -1.2574e-01, -8.3570e-01, -9.4050e-01,\n",
       "           -9.1811e-01, -6.4195e-01, -4.6085e-01,  8.4565e-01, -6.2729e-01,\n",
       "            7.0256e-01, -9.4780e-01, -2.1636e+00,  1.0744e+00, -9.1201e-01,\n",
       "            1.5974e-01,  6.9043e-01,  1.9181e-01, -6.0503e-01, -9.4888e-02,\n",
       "            1.6755e+00, -6.6401e-01, -9.3039e-02, -3.2811e+00, -1.1339e+00,\n",
       "           -1.4977e+00,  2.0974e+00,  2.8592e+00, -1.1878e+00,  3.1031e-01,\n",
       "           -7.5878e-02, -9.0169e-01,  1.2419e+00,  3.4741e-01,  3.5473e-02,\n",
       "           -9.7203e-01, -1.3963e+00, -1.2848e+00,  8.2326e-01,  4.4030e-01,\n",
       "           -1.2306e+00, -4.7547e-01,  3.7889e-01, -1.8067e+00,  1.4543e-01,\n",
       "           -1.0431e+00,  2.6095e-01,  4.6773e-01,  5.7089e-02, -3.9014e-02,\n",
       "            2.9518e-02, -1.8958e-01, -6.8747e-01,  9.1684e-01,  7.9944e-01,\n",
       "           -2.4989e+00,  2.0805e+00,  1.9911e-01, -5.0456e-01, -1.2684e+00,\n",
       "            7.8351e-01,  2.0641e+00, -9.0842e-01,  4.8274e-01,  1.7484e-01,\n",
       "            1.3864e+00,  1.1372e+00, -1.9198e+00, -2.6661e-01, -1.3542e+00,\n",
       "           -1.3602e+00, -1.8916e-01, -1.0044e+00,  7.6201e-01]]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[-1.2719,  1.1333,  0.0443,  ...,  0.6008,  0.1514, -0.0119]],\n",
       "\n",
       "          [[-0.1083, -0.1909,  1.1390,  ...,  0.9228,  0.3081,  0.4741]],\n",
       "\n",
       "          [[-0.8484, -0.1518, -0.9177,  ...,  0.4169,  0.0515, -0.9480]],\n",
       "\n",
       "          [[-0.5884, -0.7237, -0.7027,  ..., -0.1708,  0.0792,  0.2196]]],\n",
       "\n",
       "\n",
       "         [[[-1.2719,  1.1333,  0.0443,  ...,  0.6188,  0.1511, -0.0147]],\n",
       "\n",
       "          [[-0.1083, -0.1909,  1.1390,  ...,  0.9085,  0.3168,  0.4683]],\n",
       "\n",
       "          [[-0.8484, -0.1518, -0.9177,  ...,  0.4179,  0.0340, -0.9488]],\n",
       "\n",
       "          [[-0.5884, -0.7237, -0.7027,  ..., -0.2246,  0.0833,  0.2181]]],\n",
       "\n",
       "\n",
       "         [[[-1.2719,  1.1333,  0.0443,  ...,  0.6366,  0.1508, -0.0175]],\n",
       "\n",
       "          [[-0.1083, -0.1909,  1.1390,  ...,  0.8938,  0.3254,  0.4624]],\n",
       "\n",
       "          [[-0.8484, -0.1518, -0.9177,  ...,  0.4188,  0.0165, -0.9492]],\n",
       "\n",
       "          [[-0.5884, -0.7237, -0.7027,  ..., -0.2784,  0.0873,  0.2165]]],\n",
       "\n",
       "\n",
       "         ...,\n",
       "\n",
       "\n",
       "         [[[ 1.4554,  0.8853,  1.9845,  ...,  0.9706,  0.1303, -0.0780]],\n",
       "\n",
       "          [[-0.1509,  0.1593,  0.8967,  ...,  0.4799,  0.4868,  0.2877]],\n",
       "\n",
       "          [[ 0.1027,  0.8557, -0.7148,  ...,  0.3971, -0.3754, -0.8720]],\n",
       "\n",
       "          [[-0.5203,  0.7742, -0.2757,  ..., -1.4481,  0.1686,  0.1615]]],\n",
       "\n",
       "\n",
       "         [[[ 1.4554,  0.8853,  1.9845,  ...,  0.9813,  0.1288, -0.0804]],\n",
       "\n",
       "          [[-0.1509,  0.1593,  0.8967,  ...,  0.4592,  0.4920,  0.2787]],\n",
       "\n",
       "          [[ 0.1027,  0.8557, -0.7148,  ...,  0.3944, -0.3914, -0.8650]],\n",
       "\n",
       "          [[-0.5203,  0.7742, -0.2757,  ..., -1.4943,  0.1716,  0.1583]]],\n",
       "\n",
       "\n",
       "         [[[ 1.4554,  0.8853,  1.9845,  ...,  0.9917,  0.1273, -0.0827]],\n",
       "\n",
       "          [[-0.1509,  0.1593,  0.8967,  ...,  0.4384,  0.4971,  0.2696]],\n",
       "\n",
       "          [[ 0.1027,  0.8557, -0.7148,  ...,  0.3915, -0.4072, -0.8576]],\n",
       "\n",
       "          [[-0.5203,  0.7742, -0.2757,  ..., -1.5398,  0.1744,  0.1552]]]]],\n",
       "       grad_fn=<UnsafeViewBackward>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(q, k.transpose(-1, -2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1.], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodings[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
